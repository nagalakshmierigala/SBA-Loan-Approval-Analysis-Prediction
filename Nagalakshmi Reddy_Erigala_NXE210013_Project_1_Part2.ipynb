{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e183c659",
   "metadata": {},
   "source": [
    "# Scoring Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "55b4d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import category_encoders as ce\n",
    "import pickle\n",
    "\n",
    "def project_1_scoring(input_data: pd.DataFrame):\n",
    "    # Load the saved model and encoders\n",
    "    logreg = joblib.load('./artifacts/LogisticRegressionModel.pkl')  # Load the trained logistic regression model\n",
    "    pca_obj = joblib.load('./artifacts/pca_obj.pkl')  # Load the PCA object\n",
    "    onehot_encoder = joblib.load('./artifacts/one_hot_encoder.pkl')  # Load the one-hot encoder object\n",
    "    woe_encoder = joblib.load('./artifacts/woe_encoder.pkl')  # Load the WOE encoder object\n",
    "    glm_model = joblib.load('./artifacts/glm.pkl')  # Load the GLM model\n",
    "\n",
    "    # Following the same preprocess steps that followed in project1 \n",
    "    \n",
    "    # Remove the 'index' column\n",
    "    input_data = input_data.drop('index', axis=1)  # Drop the 'index' column\n",
    "    \n",
    "    # Replace encode Na/Null values\n",
    "    input_data.fillna(0, inplace=True)  # Replace null/missing values with 0\n",
    "    \n",
    "    # Convert the dollar columns from string format to float format\n",
    "    dollar_columns = ['DisbursementGross', 'BalanceGross', 'GrAppv', 'SBA_Appv']\n",
    "    for col in dollar_columns:\n",
    "        input_data[col] = [float(val[1:].replace(',', '')) for val in input_data[col].values]\n",
    "\n",
    "    # Convert MIS_Status to 0/1. Make value \"CHGOFF\" as 1\n",
    "    input_data['MIS_Status'] = (input_data['MIS_Status'] == 'CHGOFF').astype(int)  # Convert 'MIS_Status' to binary\n",
    "    \n",
    "    # One-hot encoding to the data and transform it\n",
    "    input_data = onehot_encoder.transform(input_data)  # Apply one-hot encoding to input data\n",
    "    \n",
    "    # WOE encoding\n",
    "    input_data = woe_encoder.transform(input_data)  # Apply WOE encoding to input data\n",
    "    # Append '_woe' to the column names of the WOE-encoded columns\n",
    "    input_data = input_data.add_suffix('_woe')\n",
    "    \n",
    "    # PCA transformation\n",
    "    input_data_pca = pca_obj.transform(input_data.drop('MIS_Status_woe',axis=1))  # Perform PCA transformation on input data\n",
    "    \n",
    "    # GLM transformation\n",
    "    input_data_glm = glm_model.predict(input_data[['Term_woe', 'SBA_Appv_woe', 'CreateJob_woe', 'NoEmp_woe', 'GrAppv_woe']])  # Perform GLM transformation on input data\n",
    "    \n",
    "    # Add PCA and GLM columns\n",
    "    def add_pca_glm_columns(input_data, pca_data, glm_data):\n",
    "        for i in range(5):\n",
    "            input_data[f\"pca{i+1}\"] = pca_data[:, i]\n",
    "        input_data[\"GLM1\"] = glm_data\n",
    "        features = ['Term_woe', 'SBA_Appv_woe', 'UrbanRural_woe', 'NoEmp_woe', 'GrAppv_woe']\n",
    "        for i, feature in enumerate(features):\n",
    "            input_data[f\"GLM{i+2}\"] = glm_data * input_data[feature]\n",
    "    add_pca_glm_columns(input_data, input_data_pca, input_data_glm)  # Add PCA and GLM columns to input data\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    Y_pred_prob = logreg.predict_proba(input_data.drop('MIS_Status_woe',axis=1))[:, 1]  # Predict class probabilities for input data\n",
    "    Y_pred_class = (Y_pred_prob >= 0.4).astype(int)  # Predict class using class probabilities\n",
    "\n",
    "    # Create the output DataFrame\n",
    "    output_data = pd.DataFrame({\n",
    "        \"record_index\": input_data.index,\n",
    "        \"predicted_class\": Y_pred_class,\n",
    "        \"probability_0\": 1 - Y_pred_prob,\n",
    "        \"probability_1\": Y_pred_prob\n",
    "    })\n",
    "\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb2b17eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   record_index  predicted_class  probability_0  probability_1\n",
      "0             0                0       0.999940       0.000060\n",
      "1             1                0       0.998103       0.001897\n",
      "2             2                0       0.989954       0.010046\n",
      "3             3                0       0.998648       0.001352\n",
      "4             4                0       0.979053       0.020947\n"
     ]
    }
   ],
   "source": [
    "# Load new data and remove the target column (if it's present)\n",
    "import pandas as pd\n",
    "import pickle\n",
    "data1 = pd.read_csv('SBA_loans_project_1.zip')\n",
    "\n",
    "# Get predictions using the scoring function\n",
    "results_data = project_1_scoring(data1)\n",
    "print(results_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93922de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
